{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_MVS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1WgR0oMVSbKqhxSb2GYmfhP4lRycNViSf",
      "authorship_tag": "ABX9TyP0v+vSGLt7xsCDEA9qOZIh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TSffer/Topicos-IA/blob/master/MLP_MVS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syJw0uZgkKl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm, datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29qbZQB1khV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Leer_Datos(filename): \n",
        "    data = pd.read_csv(filename, sep=',', header=None).to_numpy()\n",
        "    return data\n",
        "\n",
        "def Normalizar_Datos(data):\n",
        "    meam_data = data.mean(axis=0)\n",
        "    std_data = data.std(axis=0)\n",
        "    normalization_t = data - meam_data\n",
        "    normalization_t = normalization_t / std_data\n",
        "    return normalization_t\n",
        "\n",
        "def Separar_X_y(data):\n",
        "    n = data.shape[1]\n",
        "    X = data[:, :n-1]\n",
        "    y = data[:, n-1:]\n",
        "    return X, y\n",
        "\n",
        "def accuracy(y_, prediction):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for i in range(len(y_)):\n",
        "        y_pred.append(np.argmax(prediction[i]))\n",
        "        y_true.append(np.argmax(y_[i]))\n",
        "\n",
        "    num_correct = 0\n",
        "    for i in range(len(y_)):\n",
        "        if(y_pred[i] == y_true[i]):\n",
        "            num_correct += 1\n",
        "    return num_correct /len(y_)   \n",
        "\n",
        "def k_fols(data, k):\n",
        "    data_n = Normalizar_Datos(data[:,0:data.shape[1]-1])\n",
        "    print('Sub_matriz: ',data_n.shape)\n",
        "    y =  data[:,-1]    \n",
        "    print('Sin normalizar: ',data.shape)\n",
        "    \n",
        "    data = np.column_stack((data_n, y))\n",
        "\n",
        "    print('Con normalizar: ', data.shape)\n",
        "    clase_0 = np.count_nonzero( y == 0)\n",
        "    clase_1 = np.count_nonzero( y == 1)\n",
        "    clase_2 = np.count_nonzero( y == 2)\n",
        "\n",
        "    div0 = int(clase_0/k)\n",
        "    div1 = int(clase_1/k)\n",
        "    div2 = int(clase_2/k)\n",
        "    print('clase 0: ', div0)\n",
        "    print('clase 1: ', div1)\n",
        "    print('clase 2: ', div2)\n",
        "\n",
        "    class_0 = data[0:clase_0, :]\n",
        "    class_1 = data[clase_0:clase_0+clase_1, :]\n",
        "    class_2 = data[clase_0+clase_1:clase_0+clase_1+clase_2, :]\n",
        "\n",
        "    np.random.shuffle(class_0)\n",
        "    np.random.shuffle(class_1)\n",
        "    np.random.shuffle(class_2)\n",
        "    \n",
        "    size_fold = int(data.shape[0] / k)\n",
        "    remainder_size_fold = int(data.shape[0] % k)\n",
        "    data = data[:data.shape[0] - remainder_size_fold, :]\n",
        "\n",
        "    k_fols = []\n",
        "    idx_row0 = 0\n",
        "    idx_row1 = 0\n",
        "    idx_row2 = 0\n",
        "    for i in range(k):\n",
        "        X0 = class_0[idx_row0:idx_row0+div0, :]\n",
        "        X1 = class_1[idx_row1:idx_row1+div1, :]\n",
        "        X2 = class_2[idx_row2:idx_row2+div2, :]\n",
        "        X = np.concatenate((X0, X1, X2))\n",
        "        k_fols.append(X)\n",
        "        idx_row0 += div0\n",
        "        idx_row1 += div1\n",
        "        idx_row2 += div2\n",
        "    return k_fols, size_fold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzBjZv6Zlp85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Crear_Entrenamiento_Prueba(k):\n",
        "    data = datasets.load_iris()\n",
        "    x = data[\"data\"]\n",
        "    y = data[\"target\"]\n",
        "    y = y.reshape((150, 1))\n",
        "    data = np.column_stack((x, y))\n",
        "    k_f, siz = k_fols(data, k)\n",
        "\n",
        "    for i in range(k):\n",
        "        np.savetxt('/content/drive/My Drive/MVS_PM/fold_'+str(i)+'.csv', k_f[i], delimiter=',')\n",
        "#Crear_Entrenamiento_Prueba(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFRqxgVRmELp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Sigmoid_(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def dS(z):\n",
        "    return Sigmoid_(z) * (1 - Sigmoid_(z))\n",
        "    \n",
        "def delta(y_true, y_pred):\n",
        "    return (y_pred - y_true) * dS(y_pred)\n",
        "\n",
        "def Crear_w(dimensions):\n",
        "    n_layers = len(dimensions)\n",
        "    w = {}\n",
        "    b = {}\n",
        "\n",
        "    #print(n_layers)\n",
        "    for i in range(len(dimensions) - 1):\n",
        "        w[i + 1] = np.random.randn(dimensions[i], dimensions[i + 1]) / np.sqrt(dimensions[i])\n",
        "        b[i + 1] = np.zeros(dimensions[i + 1])\n",
        "\n",
        "    return w, b, n_layers \n",
        "        \n",
        "\n",
        "def Forward(x, w, b, n_layers):\n",
        "    z = {}\n",
        "    A = {1: x}\n",
        "\n",
        "    for i in range(1, n_layers):\n",
        "        z[i+1] = np.dot(A[i], w[i]) + b[i]\n",
        "        A[i+1] = Sigmoid_(z[i+1])\n",
        "        \n",
        "    return z, A\n",
        "\n",
        "def Backward(z, A, y, w, b, learning_rate, n_layers):\n",
        "    delta_ = delta(y, A[n_layers])\n",
        "    dw = np.dot(A[n_layers-1].T, delta_)\n",
        "\n",
        "    update_params = {\n",
        "        n_layers - 1: (dw, delta_)\n",
        "    }\n",
        "\n",
        "    for i in reversed(range(2, n_layers)):\n",
        "        delta_ = np.dot(delta_, w[i].T) * dS(z[i])\n",
        "        dw = np.dot(A[i-1].T, delta_)\n",
        "        update_params[i-1] = (dw, delta_)\n",
        "        \n",
        "    for k, v in update_params.items():\n",
        "        w[k] -= learning_rate * v[0]\n",
        "        b[k] -= learning_rate * np.mean(v[1], 0) \n",
        "    \n",
        "    return w, b\n",
        "        \n",
        "def predict(x, w, b, n_layers):\n",
        "    _, a = Forward(x, w, b, n_layers)\n",
        "    return a[n_layers]\n",
        "\n",
        "def Costs(y_true, y_pred):\n",
        "    return np.mean((y_pred - y_true)**2)\n",
        "\n",
        "def Calcular_Funcion_Costo(A, y):\n",
        "    result = np.sum((y * np.log(A)) + ((1 - y) * np.log(1-A)))\n",
        "    result = (-result)/y.shape[0]\n",
        "    #print(\"y.shape[1]\", y.shape[1])\n",
        "    return np.mean(result)\n",
        "\n",
        "def Gradiente_Descendiente(x, y, w, b, n_layers,epochs, learning_rate = 1e-3):\n",
        "    if not x.shape[0] == y.shape[0]:\n",
        "        raise ValueError(\"Length of x and y arrays dont's match\")\n",
        "    \n",
        "    cost_h = np.zeros(epochs)\n",
        "\n",
        "    for i in range(epochs):\n",
        "        z, a = Forward(x, w, b, n_layers)\n",
        "        w, b = Backward(z, a, y, w, b, learning_rate, n_layers)\n",
        "        #cost_h[i] = Calcular_Funcion_Costo(a[n_layers], y)\n",
        "        cost_h[i] = Costs(y, a[n_layers])\n",
        "        #    _, a = Forward(x, w, b, n_layers)\n",
        "    return w, b, cost_h\n",
        "                    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBhmMKiBmYxT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b925475-e9be-4eca-afa8-1e49c67fc2fb"
      },
      "source": [
        "# Experimento 1\n",
        "\n",
        "def EXP1(filename, dataname, arq):\n",
        "    k_fols = []\n",
        "    \n",
        "    for i in range(3):\n",
        "        X = Leer_Datos(filename +'/fold_'+str(i)+'.csv')\n",
        "        k_fols.append(X)\n",
        "    \n",
        "    for conf in arq:\n",
        "        apr = np.array([0.01, 0.05, 0.1, 0.2, 0.3, 0.4])\n",
        "        s = 0\n",
        "        sum_acc = 0\n",
        "        acc = np.zeros((7,6), float)\n",
        "\n",
        "        w, b, n_layers = Crear_w(conf)\n",
        "\n",
        "        for it in range(500,4000,500):\n",
        "            for i in range(len(apr)):\n",
        "                for k in range(3):\n",
        "                    data_train = np.concatenate((k_fols[(k+1)%3], k_fols[(k+2)%3]))\n",
        "                    data_test = k_fols[k]\n",
        "                    train_x, train_y = Separar_X_y(data_train)\n",
        "                    train_y = train_y.reshape(train_y.shape[0])\n",
        "                    train_y = np.eye(conf[len(conf)-1])[train_y.astype(int)]\n",
        "                    test_x, test_y = Separar_X_y(data_test)\n",
        "                    test_y = test_y.reshape(test_y.shape[0])\n",
        "                    test_y = np.eye(conf[len(conf)-1])[test_y.astype(int)]\n",
        "                    \n",
        "                    w, b, cost_h = Gradiente_Descendiente(train_x, train_y, w, b, n_layers, 1000, learning_rate = 0.01)\n",
        "                    prediction = predict(test_x, w, b, n_layers)\n",
        "                    #nn.fit(train_x, train_y, loss = MSE, epochs=it, batch_size=150, learning_rate=apr[i])\n",
        "                    #prediction = nn.predict(test_x)\n",
        "                    sum_acc += accuracy(test_y, prediction)\n",
        "                acc[s,i] = sum_acc/3\n",
        "                sum_acc = 0.0\n",
        "            s = s + 1  \n",
        "        \n",
        "        print(\"Conjunto de Datos: \" + dataname + \"       Aquitectura: \", conf)\n",
        "        fils = [\"iter: 500\", \"iter: 1000\", \"iter: 1500\", \"iter: 2000\", \"iter: 2500\", \"iter: 3000\", \"iter: 3500\"]\n",
        "        cols = [\"α: 0.01\", \"α: 0.05\", \"α: 0.1\", \"α: 0.2\", \"α: 0.3\", \"α: 0.4\"]\n",
        "        df = pd.DataFrame(acc, columns=cols, index=fils)\n",
        "\n",
        "        print(df)\n",
        "        print('\\n')\n",
        "\n",
        "# Dataset Iris\n",
        "arquitecture1 = [(4, 4, 3), (4, 1, 2, 3), (4, 1, 2, 3, 3)]\n",
        "arquitecture2 = [(4, 2, 3), (4, 2, 3, 3), (4, 4, 5, 4, 3)]\n",
        "\n",
        "# Dataset Enfermedad Cardiaca\n",
        "arquitecture3 = [(13, 3, 2), (13, 3, 3, 2), (13, 5, 7, 3, 2)]\n",
        "arquitecture4 = [(13, 13, 2), (13, 13, 15, 2), (13, 4, 15, 4, 2)]\n",
        "\n",
        "EXP1(\"/content/drive/My Drive/MVS_PM\", \"Iris\", arquitecture1)\n",
        "EXP1(\"/content/drive/My Drive/MVS_PM\", \"Iris\", arquitecture2)\n",
        "\n",
        "EXP1(\"/content/drive/My Drive/MVS_PM/Enfermedad_Cardiaca_Data\", \"Enfermedades Cardiaca\", arquitecture3)\n",
        "EXP1(\"/content/drive/My Drive/MVS_PM/Enfermedad_Cardiaca_Data\", \"Enfermedades Cardiaca\", arquitecture4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conjunto de Datos: Iris       Aquitectura:  (4, 4, 3)\n",
            "             α: 0.01   α: 0.05    α: 0.1    α: 0.2    α: 0.3    α: 0.4\n",
            "iter: 500   0.923611  0.965278  0.965278  0.965278  0.965278  0.965278\n",
            "iter: 1000  0.965278  0.965278  0.965278  0.958333  0.958333  0.958333\n",
            "iter: 1500  0.958333  0.958333  0.958333  0.958333  0.958333  0.965278\n",
            "iter: 2000  0.965278  0.965278  0.965278  0.965278  0.965278  0.965278\n",
            "iter: 2500  0.965278  0.965278  0.965278  0.965278  0.965278  0.965278\n",
            "iter: 3000  0.965278  0.965278  0.965278  0.965278  0.965278  0.972222\n",
            "iter: 3500  0.979167  0.979167  0.979167  0.986111  0.986111  0.986111\n",
            "\n",
            "\n",
            "Conjunto de Datos: Iris       Aquitectura:  (4, 1, 2, 3)\n",
            "             α: 0.01   α: 0.05    α: 0.1    α: 0.2    α: 0.3    α: 0.4\n",
            "iter: 500   0.833333  0.958333  0.965278  0.965278  0.965278  0.965278\n",
            "iter: 1000  0.958333  0.958333  0.958333  0.965278  0.965278  0.972222\n",
            "iter: 1500  0.972222  0.972222  0.972222  0.972222  0.979167  0.979167\n",
            "iter: 2000  0.979167  0.979167  0.979167  0.979167  0.979167  0.979167\n",
            "iter: 2500  0.979167  0.979167  0.979167  0.979167  0.979167  0.979167\n",
            "iter: 3000  0.979167  0.979167  0.979167  0.979167  0.979167  0.979167\n",
            "iter: 3500  0.979167  0.979167  0.979167  0.986111  0.986111  0.986111\n",
            "\n",
            "\n",
            "Conjunto de Datos: Iris       Aquitectura:  (4, 1, 2, 3, 3)\n",
            "             α: 0.01   α: 0.05    α: 0.1    α: 0.2    α: 0.3    α: 0.4\n",
            "iter: 500   0.729167  0.923611  0.958333  0.979167  0.979167  0.979167\n",
            "iter: 1000  0.979167  0.972222  0.972222  0.972222  0.986111  0.986111\n",
            "iter: 1500  0.986111  0.979167  0.986111  0.986111  0.979167  0.979167\n",
            "iter: 2000  0.986111  0.986111  0.979167  0.979167  0.986111  0.986111\n",
            "iter: 2500  0.986111  0.986111  0.979167  0.979167  0.979167  0.979167\n",
            "iter: 3000  0.979167  0.979167  0.979167  0.979167  0.979167  0.979167\n",
            "iter: 3500  0.979167  0.979167  0.979167  0.979167  0.979167  0.979167\n",
            "\n",
            "\n",
            "Conjunto de Datos: Iris       Aquitectura:  (4, 2, 3)\n",
            "             α: 0.01   α: 0.05    α: 0.1    α: 0.2    α: 0.3    α: 0.4\n",
            "iter: 500   0.909722  0.951389  0.965278  0.972222  0.972222  0.972222\n",
            "iter: 1000  0.972222  0.972222  0.972222  0.972222  0.972222  0.972222\n",
            "iter: 1500  0.979167  0.979167  0.979167  0.979167  0.979167  0.979167\n",
            "iter: 2000  0.979167  0.979167  0.979167  0.979167  0.979167  0.979167\n",
            "iter: 2500  0.979167  0.979167  0.979167  0.979167  0.979167  0.979167\n",
            "iter: 3000  0.979167  0.979167  0.979167  0.979167  0.979167  0.979167\n",
            "iter: 3500  0.979167  0.979167  0.979167  0.979167  0.979167  0.979167\n",
            "\n",
            "\n",
            "Conjunto de Datos: Iris       Aquitectura:  (4, 2, 3, 3)\n",
            "             α: 0.01   α: 0.05    α: 0.1    α: 0.2    α: 0.3    α: 0.4\n",
            "iter: 500   0.958333  0.972222  0.979167  0.979167  0.979167  0.979167\n",
            "iter: 1000  0.979167  0.979167  0.979167  0.979167  0.979167  0.979167\n",
            "iter: 1500  0.979167  0.979167  0.979167  0.979167  0.979167  0.979167\n",
            "iter: 2000  0.979167  0.979167  0.979167  0.979167  0.979167  0.979167\n",
            "iter: 2500  0.979167  0.979167  0.979167  0.979167  0.979167  0.979167\n",
            "iter: 3000  0.979167  0.979167  0.979167  0.979167  0.979167  0.979167\n",
            "iter: 3500  0.979167  0.979167  0.979167  0.979167  0.979167  0.979167\n",
            "\n",
            "\n",
            "Conjunto de Datos: Iris       Aquitectura:  (4, 4, 5, 4, 3)\n",
            "             α: 0.01   α: 0.05    α: 0.1    α: 0.2    α: 0.3    α: 0.4\n",
            "iter: 500   0.875000  0.965278  0.965278  0.965278  0.965278  0.965278\n",
            "iter: 1000  0.965278  0.965278  0.965278  0.972222  0.972222  0.972222\n",
            "iter: 1500  0.979167  0.979167  0.979167  0.972222  0.972222  0.965278\n",
            "iter: 2000  0.958333  0.972222  0.979167  0.979167  0.979167  0.979167\n",
            "iter: 2500  0.993056  0.993056  0.993056  0.993056  0.993056  1.000000\n",
            "iter: 3000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000\n",
            "iter: 3500  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000\n",
            "\n",
            "\n",
            "Conjunto de Datos: Enfermedades Cardiaca       Aquitectura:  (13, 3, 2)\n",
            "             α: 0.01   α: 0.05    α: 0.1    α: 0.2    α: 0.3    α: 0.4\n",
            "iter: 500   0.854785  0.864686  0.871287  0.874587  0.877888  0.884488\n",
            "iter: 1000  0.891089  0.900990  0.904290  0.904290  0.904290  0.904290\n",
            "iter: 1500  0.904290  0.904290  0.907591  0.910891  0.910891  0.910891\n",
            "iter: 2000  0.910891  0.914191  0.914191  0.917492  0.917492  0.917492\n",
            "iter: 2500  0.917492  0.917492  0.917492  0.920792  0.920792  0.920792\n",
            "iter: 3000  0.920792  0.920792  0.920792  0.920792  0.920792  0.920792\n",
            "iter: 3500  0.924092  0.924092  0.924092  0.924092  0.924092  0.924092\n",
            "\n",
            "\n",
            "Conjunto de Datos: Enfermedades Cardiaca       Aquitectura:  (13, 3, 3, 2)\n",
            "             α: 0.01   α: 0.05    α: 0.1    α: 0.2    α: 0.3    α: 0.4\n",
            "iter: 500   0.834983  0.828383  0.854785  0.864686  0.887789  0.900990\n",
            "iter: 1000  0.907591  0.904290  0.900990  0.894389  0.884488  0.881188\n",
            "iter: 1500  0.874587  0.874587  0.881188  0.881188  0.881188  0.884488\n",
            "iter: 2000  0.884488  0.887789  0.887789  0.881188  0.881188  0.881188\n",
            "iter: 2500  0.881188  0.881188  0.881188  0.881188  0.884488  0.887789\n",
            "iter: 3000  0.891089  0.900990  0.900990  0.910891  0.910891  0.914191\n",
            "iter: 3500  0.914191  0.907591  0.907591  0.920792  0.930693  0.933993\n",
            "\n",
            "\n",
            "Conjunto de Datos: Enfermedades Cardiaca       Aquitectura:  (13, 5, 7, 3, 2)\n",
            "             α: 0.01   α: 0.05    α: 0.1    α: 0.2    α: 0.3    α: 0.4\n",
            "iter: 500   0.858086  0.900990  0.864686  0.834983  0.851485  0.867987\n",
            "iter: 1000  0.887789  0.877888  0.910891  0.904290  0.927393  0.933993\n",
            "iter: 1500  0.937294  0.884488  0.940594  0.960396  0.960396  0.900990\n",
            "iter: 2000  0.891089  0.877888  0.900990  0.891089  0.861386  0.871287\n",
            "iter: 2500  0.887789  0.887789  0.891089  0.871287  0.920792  0.910891\n",
            "iter: 3000  0.917492  0.930693  0.933993  0.920792  0.881188  0.894389\n",
            "iter: 3500  0.904290  0.914191  0.933993  0.937294  0.947195  0.930693\n",
            "\n",
            "\n",
            "Conjunto de Datos: Enfermedades Cardiaca       Aquitectura:  (13, 13, 2)\n",
            "             α: 0.01   α: 0.05    α: 0.1    α: 0.2  α: 0.3  α: 0.4\n",
            "iter: 500   0.854785  0.927393  0.963696  0.993399     1.0     1.0\n",
            "iter: 1000  1.000000  1.000000  1.000000  1.000000     1.0     1.0\n",
            "iter: 1500  1.000000  1.000000  1.000000  1.000000     1.0     1.0\n",
            "iter: 2000  1.000000  1.000000  1.000000  1.000000     1.0     1.0\n",
            "iter: 2500  1.000000  1.000000  1.000000  1.000000     1.0     1.0\n",
            "iter: 3000  1.000000  1.000000  1.000000  1.000000     1.0     1.0\n",
            "iter: 3500  1.000000  1.000000  1.000000  1.000000     1.0     1.0\n",
            "\n",
            "\n",
            "Conjunto de Datos: Enfermedades Cardiaca       Aquitectura:  (13, 13, 15, 2)\n",
            "             α: 0.01   α: 0.05  α: 0.1  α: 0.2  α: 0.3  α: 0.4\n",
            "iter: 500   0.834983  0.973597  0.9967     1.0     1.0     1.0\n",
            "iter: 1000  1.000000  1.000000  1.0000     1.0     1.0     1.0\n",
            "iter: 1500  1.000000  1.000000  1.0000     1.0     1.0     1.0\n",
            "iter: 2000  1.000000  1.000000  1.0000     1.0     1.0     1.0\n",
            "iter: 2500  1.000000  1.000000  1.0000     1.0     1.0     1.0\n",
            "iter: 3000  1.000000  1.000000  1.0000     1.0     1.0     1.0\n",
            "iter: 3500  1.000000  1.000000  1.0000     1.0     1.0     1.0\n",
            "\n",
            "\n",
            "Conjunto de Datos: Enfermedades Cardiaca       Aquitectura:  (13, 4, 15, 4, 2)\n",
            "             α: 0.01   α: 0.05    α: 0.1    α: 0.2    α: 0.3    α: 0.4\n",
            "iter: 500   0.841584  0.861386  0.858086  0.851485  0.841584  0.762376\n",
            "iter: 1000  0.775578  0.841584  0.811881  0.844884  0.841584  0.828383\n",
            "iter: 1500  0.782178  0.811881  0.815182  0.825083  0.844884  0.828383\n",
            "iter: 2000  0.815182  0.792079  0.795380  0.825083  0.801980  0.848185\n",
            "iter: 2500  0.844884  0.808581  0.828383  0.838284  0.848185  0.831683\n",
            "iter: 3000  0.838284  0.851485  0.844884  0.848185  0.841584  0.848185\n",
            "iter: 3500  0.867987  0.858086  0.808581  0.841584  0.834983  0.801980\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuzyEIw2mqkQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "4a62a377-f399-4910-b2e9-eb3401ddeb81"
      },
      "source": [
        "# Experimento 2\n",
        "\n",
        "def EXP2(filename, dataname):\n",
        "    kernels = ['linear', 'poly', 'rbf']\n",
        "    C = np.array([2500.0, 1000.0, 100.0, 1.0, 0.5, 0.01])\n",
        "\n",
        "    k_fols = []\n",
        "    for i in range(3):\n",
        "        X = Leer_Datos(filename +'/fold_'+str(i)+'.csv')\n",
        "        k_fols.append(X)\n",
        "    \n",
        "    s = 0\n",
        "    sum_acc = 0\n",
        "    acc = np.zeros((6,3), float)\n",
        "\n",
        "    for c in C:\n",
        "        for i in range(len(kernels)):\n",
        "            for k in range(3):\n",
        "                data_train = np.concatenate((k_fols[(k+1)%3], k_fols[(k+2)%3]))\n",
        "                data_test = k_fols[k]\n",
        "                train_x, train_y = Separar_X_y(data_train)          \n",
        "                test_x, test_y = Separar_X_y(data_test)\n",
        "                model = svm.SVC(C=c, kernel=kernels[i], gamma='scale')\n",
        "                model.fit(train_x, train_y.reshape(train_y.shape[0]))\n",
        "                acc_test = model.score(test_x, test_y.reshape(test_y.shape[0]))\n",
        "                \n",
        "                \n",
        "                sum_acc += acc_test\n",
        "            \n",
        "            acc[s,i] = sum_acc/3\n",
        "            sum_acc = 0.0\n",
        "        s = s + 1  \n",
        "\n",
        "    print(\"Conjunto de Datos: \" + dataname)\n",
        "    fils = [\"C: 2500.0\", \"C: 1000.0\", \"C: 100.0\", \"C: 1.0\", \"C: 0.5\", \"C: 0.01\"]\n",
        "    cols = [\"Kernel: linear\", \"Kernel: poly\", \"Kernel: rbf\"]\n",
        "    df = pd.DataFrame(acc, columns=cols, index=fils)\n",
        "\n",
        "    print(df)\n",
        "    print('\\n')\n",
        "\n",
        "EXP2(\"/content/drive/My Drive/MVS_PM\", \"Iris\")\n",
        "EXP2(\"/content/drive/My Drive/MVS_PM/Enfermedad_Cardiaca_Data\", \"Enfermedad Cardiaca\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conjunto de Datos: Iris\n",
            "           Kernel: linear  Kernel: poly  Kernel: rbf\n",
            "C: 2500.0        0.986111      0.916667     0.958333\n",
            "C: 1000.0        0.979167      0.916667     0.958333\n",
            "C: 100.0         0.979167      0.958333     0.944444\n",
            "C: 1.0           0.986111      0.923611     0.965278\n",
            "C: 0.5           0.972222      0.888889     0.958333\n",
            "C: 0.01          0.868056      0.527778     0.909722\n",
            "\n",
            "\n",
            "Conjunto de Datos: Enfermedad Cardiaca\n",
            "           Kernel: linear  Kernel: poly  Kernel: rbf\n",
            "C: 2500.0        0.838284      0.745875     0.801980\n",
            "C: 1000.0        0.838284      0.745875     0.801980\n",
            "C: 100.0         0.838284      0.745875     0.801980\n",
            "C: 1.0           0.834983      0.798680     0.844884\n",
            "C: 0.5           0.838284      0.772277     0.841584\n",
            "C: 0.01          0.838284      0.544554     0.544554\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN5IpW3Vm2mB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Plot(filename, dataname, epoch, apr, model):\n",
        "    k_fols = []\n",
        "    for i in range(3):\n",
        "        X = Leer_Datos(filename +'/fold_'+str(i)+'.csv')\n",
        "        k_fols.append(X)\n",
        "\n",
        "    cl = ['b:','r:','y:']\n",
        "    cost_ht = []\n",
        "    w, b, n_layers = Crear_w(model)\n",
        "    sum_acc = 0\n",
        "  \n",
        "    data_train = np.concatenate((k_fols[0], k_fols[1], k_fols[1]))\n",
        "        \n",
        "    train_x, train_y = Separar_X_y(data_train)\n",
        "    train_y = train_y.reshape(train_y.shape[0])\n",
        "    train_y = np.eye(3)[train_y.astype(int)]\n",
        "\n",
        "    w, b, cost_h = Gradiente_Descendiente(train_x, train_y, w, b, n_layers, epoch, learning_rate = apr)\n",
        "\n",
        "    cost_ht.append(cost_h)\n",
        "        \n",
        "    plt.plot(np.arange(cost_ht[0].shape[0]),cost_ht[0], cl[0], label='Iris')\n",
        "    plt.title(dataname)\n",
        "    plt.xlabel('Iteraciones')\n",
        "    plt.ylabel('Costo')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "Plot(\"/content/drive/My Drive/MVS_PM\", \"Iris\", 3500, 0.3, (4, 3, 3))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}